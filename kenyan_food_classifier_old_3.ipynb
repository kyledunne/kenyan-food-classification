{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision import models\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torchmetrics import MeanMetric\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "# convert image tensor to PIL image and in range 0-255\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import random"
   ],
   "id": "942541630a597008"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "home_folder = ''\n",
    "# home_folder = '/kaggle/input/'\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataConfiguration:\n",
    "    data_folder = home_folder + 'data/'\n",
    "    # data_folder = home_folder + 'opencv-pytorch-project-2-classification-round-3/'\n",
    "    images_folder = data_folder + 'images/'\n",
    "    # images_folder = data_folder + 'images/images/'\n",
    "    num_workers: int = 2\n",
    "    batch_size: int = 32\n",
    "    num_classes = 13\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfiguration:\n",
    "    model_name: str = 'resnet50'\n",
    "    weights: str = \"DEFAULT\"\n",
    "    max_epochs: int = 10\n",
    "    learning_rate: float = 4e-4\n",
    "    fine_tune_start: int = 4\n",
    "    precision: str = \"32\"\n",
    "\n",
    "data_config = DataConfiguration()\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "def build_class_to_idx(class_labels) -> Dict[str, int]:\n",
    "    unique_classes = sorted(set(class_labels))\n",
    "    return {cls: idx for idx, cls in enumerate(unique_classes)}"
   ],
   "id": "391cb920de9038b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# show random images from the dataset to illustrate the classification problem\n",
    "if 'train_csv' not in locals():\n",
    "    train_csv = pd.read_csv(data_config.data_folder + 'train.csv')\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, row in train_csv.sample(10).reset_index(drop=True).iterrows():\n",
    "    img_path = f\"{data_config.images_folder}{row['id']}.jpg\"\n",
    "    img = Image.open(img_path)\n",
    "    img_width, img_height = img.size\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{row['class']} ({img_width}, {img_height})\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7269c366bb87c9a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ClassLabeledImagesDataset(TorchDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            x: pd.Series,\n",
    "            y: pd.Series,\n",
    "            class_to_idx: Dict[str, int],\n",
    "            transform: T.Compose,\n",
    "    ):\n",
    "        assert len(x) == len(y), \"x and y series must be same length\"\n",
    "        self.x = x.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True).map(class_to_idx)\n",
    "        self.transform = transform\n",
    "\n",
    "        self._paths = []\n",
    "        for id in self.x:\n",
    "            path = f'{data_config.images_folder}{id}.jpg'\n",
    "            if not Path(path).exists():\n",
    "                raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "            self._paths.append(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.transform(Image.open(self._paths[idx]).convert(\"RGB\")), self.y[idx]"
   ],
   "id": "dc9f3de6ad031d20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class KenyanFoodsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, num_workers=8, img_size=224):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.num_classes = 13\n",
    "\n",
    "        imagenet_mean = [0.485, 0.456, 0.406]\n",
    "        imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        self.preprocess_transforms = T.Compose([\n",
    "            T.Resize((img_size, img_size), antialias=True),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.common_transforms = T.Compose([\n",
    "            self.preprocess_transforms,\n",
    "            T.Normalize(imagenet_mean, imagenet_std),\n",
    "        ])\n",
    "\n",
    "        self.aug_transforms = T.Compose([\n",
    "            T.RandomResizedCrop(256),\n",
    "            T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.3),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomRotation(90),\n",
    "            T.RandomGrayscale(p=0.1),\n",
    "            self.common_transforms,\n",
    "            T.RandomErasing(),\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train = pd.read_csv(data_config.data_folder + 'train.csv')\n",
    "        x_id = train['id']\n",
    "        y = train['class']\n",
    "        x_id_train, x_id_val, y_train, y_val = train_test_split(x_id, y, random_state=42, test_size=0.2, stratify=y)\n",
    "        class_to_idx = build_class_to_idx(y)\n",
    "        self.train_ds = ClassLabeledImagesDataset(x_id_train, y_train, class_to_idx, self.aug_transforms)\n",
    "        self.val_ds = ClassLabeledImagesDataset(x_id_val, y_val, class_to_idx, self.common_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)"
   ],
   "id": "5db19f2dd09e1d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResNetFineTuningModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        resnet_model_name=\"resnet50\",\n",
    "        weights=\"DEFAULT\",\n",
    "        fine_tune_start=4,\n",
    "        learning_rate=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        resnet = getattr(models, self.hparams.resnet_model_name)(weights=self.hparams.weights)\n",
    "\n",
    "        if self.hparams.weights:\n",
    "            for param in resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            if self.hparams.fine_tune_start <= 1:\n",
    "                for param in resnet.layer1.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            if self.hparams.fine_tune_start <= 2:\n",
    "                for param in resnet.layer2.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            if self.hparams.fine_tune_start <= 3:\n",
    "                for param in resnet.layer3.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            if self.hparams.fine_tune_start <= 4:\n",
    "                for param in resnet.layer4.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        last_layer_in = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(last_layer_in, self.hparams.num_classes)\n",
    "\n",
    "        self.resnet = resnet\n",
    "\n",
    "        # Initializing the required metric objects.\n",
    "        self.mean_train_loss = MeanMetric()\n",
    "        self.mean_train_acc = MulticlassAccuracy(num_classes=self.hparams.num_classes, average=\"micro\")\n",
    "        self.mean_valid_loss = MeanMetric()\n",
    "        self.mean_valid_acc = MulticlassAccuracy(num_classes=self.hparams.num_classes, average=\"micro\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        data, target = batch\n",
    "        output = self(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        pred_batch = output.detach().argmax(dim=1)\n",
    "        self.mean_train_loss(loss, weight=data.shape[0])\n",
    "        self.mean_train_acc(pred_batch, target)\n",
    "\n",
    "        # Arguments such as on_epoch, on_step and logger are set automatically depending on\n",
    "        # the hook methods they've been called from\n",
    "        self.log(\"train/batch_loss\", self.mean_train_loss, prog_bar=True, logger=True)\n",
    "\n",
    "        # logging and adding current batch_acc to progress_bar\n",
    "        self.log(\"train/batch_acc\", self.mean_train_acc, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Calculate epoch level metrics for the train set\n",
    "        self.log(\"train/loss\", self.mean_train_loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train/acc\", self.mean_train_acc, prog_bar=True, logger=True)\n",
    "        self.log(\"step\", self.current_epoch, logger=True)\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        data, target = batch\n",
    "        output = self(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        pred_batch = output.argmax(dim=1)\n",
    "\n",
    "        # Update logs\n",
    "        self.mean_valid_loss(loss, weight=data.shape[0])\n",
    "        self.mean_valid_acc(pred_batch, target)\n",
    "\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Calculate epoch level metrics for the validation set\n",
    "        self.log(\"valid/loss\", self.mean_valid_loss, prog_bar=True, logger=True)\n",
    "        self.log(\"valid/acc\", self.mean_valid_acc, prog_bar=True, logger=True)\n",
    "        self.log(\"step\", self.current_epoch, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        # example of using scheduler\n",
    "        # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "        #\n",
    "        # return {\n",
    "        #     \"optimizer\": optimizer,\n",
    "        #     \"lr_scheduler\": scheduler,\n",
    "        #     \"monitor\": \"val_loss\",  # optional for ReduceLROnPlateau\n",
    "        # }\n",
    "        return optimizer"
   ],
   "id": "59cf02f5e52e724c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_training():\n",
    "    pl.seed_everything(42, workers=True)\n",
    "\n",
    "    # init model\n",
    "    data_module = KenyanFoodsDataModule(\n",
    "        batch_size=data_config.batch_size, num_workers=data_config.num_workers\n",
    "    )\n",
    "\n",
    "    model = ResNetFineTuningModule(\n",
    "        resnet_model_name=train_config.model_name,\n",
    "        weights=train_config.weights,\n",
    "        fine_tune_start=train_config.fine_tune_start,\n",
    "        num_classes=data_module.num_classes,\n",
    "        learning_rate=train_config.learning_rate,\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='valid/acc',\n",
    "        mode=\"max\",\n",
    "        filename='resnet50-fine-tuning-epoch-{epoch:02d}',\n",
    "        auto_insert_metric_name=False,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"valid/loss\", patience=20)\n",
    "\n",
    "    # most basic trainer, uses good defaults\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        max_epochs=train_config.max_epochs,\n",
    "        precision = train_config.precision,\n",
    "        callbacks=[\n",
    "            early_stopping_callback,\n",
    "            checkpoint_callback,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    return model, data_module, checkpoint_callback"
   ],
   "id": "6a70295e27ff304"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model, data_module, checkpoint_callback = run_training()",
   "id": "31aac42b7309eec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def denormalize(tensors):\n",
    "    \"\"\"Denormalizes image tensors back to range [0.0, 1.0]\"\"\"\n",
    "\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.Tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    tensors = tensors.clone()\n",
    "    for c in range(3):\n",
    "        tensors[:, c, :, :].mul_(std[c]).add_(mean[c])\n",
    "\n",
    "    return torch.clamp(tensors.cpu(), 0.0, 1.0)\n",
    "\n",
    "\n",
    "def sample_prediction(model, data_module, ckpt_path):\n",
    "    random.seed(1)\n",
    "\n",
    "    # load model from checkpoint\n",
    "    ckpt_model = ResNetFineTuningModule.load_from_checkpoint(ckpt_path)\n",
    "    # freeze model for inference\n",
    "    ckpt_model.freeze()\n",
    "\n",
    "    # run model in evaluation mode\n",
    "    ckpt_model.eval()\n",
    "\n",
    "    # get val_dataloader for data_module\n",
    "    val_data = data_module.val_dataloader()\n",
    "\n",
    "    idx_to_class = {j: i for i, j in class_to_idx_final.items()}\n",
    "\n",
    "    imgs = []\n",
    "    preds = []\n",
    "    probs = []\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    ckpt_model.to(device)\n",
    "\n",
    "    for data, _ in val_data:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = ckpt_model(data.to(device))\n",
    "\n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "\n",
    "        # get the max probability\n",
    "        pred_prob = prob.data.max(dim=1)[0]\n",
    "\n",
    "        # get the index of the max probability\n",
    "        pred_index = prob.data.max(dim=1)[1]\n",
    "        # pass the loaded model\n",
    "        pred = pred_index.cpu().tolist()\n",
    "        prob = pred_prob.cpu().tolist()\n",
    "\n",
    "        imgs.extend([np.asarray(to_pil_image(image)) for image in denormalize(data)])\n",
    "\n",
    "        preds.extend(pred)\n",
    "        probs.extend(prob)\n",
    "        break\n",
    "\n",
    "    # randomly select 6 images fom the first batch\n",
    "    random_6 = random.sample(list(zip(imgs, preds, probs)), 6)\n",
    "\n",
    "    plt.figure(figsize=(12, 15))\n",
    "\n",
    "    for idx, (img, pred, prob) in enumerate(random_6, 1):\n",
    "        img = np.array(img).reshape(224, 224, 3)\n",
    "        plt.subplot(3, 2, idx)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Prediction: {idx_to_class[pred]}, Prob: {prob:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ],
   "id": "e3ed6ef6cf7c33e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class_labels_final = pd.read_csv(data_config.data_folder + 'train.csv')['class']\n",
    "class_to_idx_final = build_class_to_idx(class_labels_final)"
   ],
   "id": "6f249d7521733d9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# get checkpoints of the latest run\n",
    "ckpt_path = checkpoint_callback.best_model_path\n",
    "print('The latest model path: {}'.format(ckpt_path))\n",
    "\n",
    "# sample prediction\n",
    "sample_prediction(model, data_module, ckpt_path)"
   ],
   "id": "330c03cd1313322f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
