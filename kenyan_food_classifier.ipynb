{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T20:39:59.858729Z",
     "start_time": "2025-12-05T20:39:59.854259Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim as TorchOptimizers\n",
    "from torchmetrics import MeanMetric\n",
    "from torchvision import models as torchmodels\n",
    "import torchvision.transforms.v2 as T\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score\n",
    "from PIL import Image, ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from torchinfo import summary as torch_summary\n",
    "import math\n",
    "import wandb"
   ],
   "outputs": [],
   "execution_count": 354
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T20:43:20.866310Z",
     "start_time": "2025-12-05T20:43:20.860310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\" A different config should be created for each device/environment \"\"\"\n",
    "    train_csv_filepath: str\n",
    "    test_csv_filepath: str\n",
    "    submission_filepath: str\n",
    "    images_root_folder: str\n",
    "    training_output_folder: str\n",
    "    saved_weights_filepath: str\n",
    "    device: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\" For configuration variables that are shared across environments \"\"\"\n",
    "        self.fine_tune_start = 5\n",
    "        self.seed = 201\n",
    "\n",
    "        self.starting_learning_rate = 4e-4\n",
    "        self.max_epochs = 150\n",
    "        self.patience = 10\n",
    "\n",
    "        self.np_dtype = np.float32\n",
    "\n",
    "        self.batch_size = 32\n",
    "        self.num_workers = 4\n",
    "        self.pin_memory = self.num_workers > 0 and self.device == 'cuda'\n",
    "\n",
    "        self.classes_list = [\n",
    "            'bhaji',\n",
    "            'chapati',\n",
    "            'githeri',\n",
    "            'kachumbari',\n",
    "            'kukuchoma',\n",
    "            'mandazi',\n",
    "            'masalachips',\n",
    "            'matoke',\n",
    "            'mukimo',\n",
    "            'nyamachoma',\n",
    "            'pilau',\n",
    "            'sukumawiki',\n",
    "            'ugali',\n",
    "        ]\n",
    "\n",
    "        self.num_classes = len(self.classes_list)\n",
    "\n",
    "        self.image_height = 300\n",
    "        self.image_width = 300\n",
    "\n",
    "    # noinspection PyAttributeOutsideInit\n",
    "    def init(self, training):\n",
    "        \"\"\" Adjust configuration setup for training vs inference \"\"\"\n",
    "        self.training = training\n",
    "        self.imagenet_mean_cpu_tensor = torch.tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_cpu_tensor = torch.tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_cpu_tensor = self.imagenet_mean_cpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_cpu_tensor = self.imagenet_std_cpu_tensor.view(3, 1, 1)\n",
    "        self.imagenet_mean_gpu_tensor = gpu_tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_gpu_tensor = gpu_tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_gpu_tensor = self.imagenet_mean_gpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_gpu_tensor = self.imagenet_std_gpu_tensor.view(3, 1, 1)\n",
    "\n",
    "        if self.training:\n",
    "            os.makedirs(self.training_output_folder, exist_ok=True)\n",
    "\n",
    "        image_dims = (self.image_height, self.image_width)\n",
    "\n",
    "        self.transforms_val = T.Compose([\n",
    "            T.Resize(size=image_dims, antialias=True),\n",
    "            T.ToImage(),\n",
    "            T.ToDtype(torch.float32, scale=True),\n",
    "            T.Normalize(self.imagenet_mean_cpu_tensor, self.imagenet_std_cpu_tensor),\n",
    "        ])\n",
    "\n",
    "        self.transforms_train = T.Compose([\n",
    "            T.ToImage(),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=180),\n",
    "            T.RandomResizedCrop(\n",
    "                size=image_dims,\n",
    "                scale=(0.6, 1.0),\n",
    "                ratio=(0.75, 1.33),\n",
    "                antialias=True,\n",
    "            ),\n",
    "            T.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.1,\n",
    "                hue=0.05,\n",
    "            ),\n",
    "            T.ToDtype(torch.float32, scale=True),\n",
    "            T.Normalize(self.imagenet_mean_cpu_tensor, self.imagenet_std_cpu_tensor),\n",
    "        ])\n",
    "\n",
    "\n",
    "config: Config = None\n",
    "\"\"\" Set to environment-relevant config before training/inference \"\"\";"
   ],
   "id": "13cd238e296dfd3b",
   "outputs": [],
   "execution_count": 356
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.792771Z",
     "start_time": "2025-12-05T19:02:23.790154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local_config = Config(\n",
    "    train_csv_filepath='data/train.csv',\n",
    "    test_csv_filepath='data/test.csv',\n",
    "    images_root_folder='data/images/',\n",
    "    submission_filepath='data_gen/submission.csv',\n",
    "    training_output_folder='data_gen/training_output/',\n",
    "    saved_weights_filepath='data_gen/training_output/model_weights.pth',\n",
    "    device='cpu',\n",
    ")\n",
    "kaggle_config = Config(\n",
    "    train_csv_filepath='/kaggle/input/opencv-pytorch-project-2-classification-round-3/train.csv',\n",
    "    test_csv_filepath='/kaggle/input/opencv-pytorch-project-2-classification-round-3/test.csv',\n",
    "    images_root_folder='/kaggle/input/opencv-pytorch-project-2-classification-round-3/images/images/',\n",
    "    submission_filepath='/kaggle/working/submission.csv',\n",
    "    training_output_folder='/kaggle/working/training_output/',\n",
    "    saved_weights_filepath='/kaggle/input/kenyan-food-classification-model-weights/model_weights.pth',\n",
    "    device='cuda',\n",
    ")"
   ],
   "id": "e933b90b9504cc3b",
   "outputs": [],
   "execution_count": 341
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.798821Z",
     "start_time": "2025-12-05T19:02:23.795776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imagenet_mean_array = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "imagenet_std_array = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def gpu_tensor(numpy_array):\n",
    "    return torch.tensor(numpy_array, device=config.device)\n",
    "\n",
    "def visualize_image(image_tensor):\n",
    "    \"\"\" Input tensor should be on gpu \"\"\"\n",
    "    image = denormalize(image_tensor, config.channelwise_imagenet_mean_gpu_tensor, config.channelwise_imagenet_std_gpu_tensor)\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    image = (image * 255).astype('uint8')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    return tensor * std + mean\n",
    "\n",
    "def load_pil_image_from_id(image_id) -> ImageFile.ImageFile:\n",
    "    return Image.open(config.images_root_folder + image_id + '.jpg')"
   ],
   "id": "3fecf34194bedc1a",
   "outputs": [],
   "execution_count": 342
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.804339Z",
     "start_time": "2025-12-05T19:02:23.801336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ImageClassificationDataset(TorchDataset):\n",
    "    image_ids: np.ndarray\n",
    "    labels: np.ndarray\n",
    "    image_transforms: Callable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pil_image = load_pil_image_from_id(self.image_ids[idx])\n",
    "        return self.image_transforms(pil_image), self.labels[idx]"
   ],
   "id": "7a9c60f8ab546924",
   "outputs": [],
   "execution_count": 343
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.809860Z",
     "start_time": "2025-12-05T19:02:23.806703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_efficient_net_model() -> nn.Module:\n",
    "    weights = 'DEFAULT' if config.training else None\n",
    "    model = torchmodels.efficientnet_b3(weights=weights)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Generally, unfreezing around layer 5 or 6 seems to work best\n",
    "    for layer_to_unfreeze in range(config.fine_tune_start, 9):\n",
    "        for param in model.features[layer_to_unfreeze].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3, inplace=True),\n",
    "        nn.Linear(in_features, config.num_classes),\n",
    "    )\n",
    "\n",
    "    model.to(config.device)\n",
    "\n",
    "    return model"
   ],
   "id": "c32ddf467b65552b",
   "outputs": [],
   "execution_count": 344
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.822994Z",
     "start_time": "2025-12-05T19:02:23.817389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_accuracy_score(preds, true):\n",
    "    # De-one-hot encode preds and true using argmax\n",
    "    preds_argmax = np.argmax(preds, axis=1)\n",
    "    true_argmax = np.argmax(true, axis=1)\n",
    "    return accuracy_score(preds_argmax, true_argmax)\n",
    "\n",
    "def train_one_epoch(start_time, model, loader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    num_batches = math.ceil(len(loader.dataset) / config.batch_size)\n",
    "    for batch_number, (x, y) in enumerate(loader):\n",
    "        print(f't={time.time() - start_time:.2f}: Loading training batch {batch_number + 1}/{num_batches}')\n",
    "\n",
    "        x = x.to(config.device, non_blocking=True)\n",
    "        y = y.to(config.device, non_blocking=True)\n",
    "\n",
    "        if batch_number == 0:\n",
    "            allocated = torch.cuda.memory_allocated(config.device) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(config.device) / 1024**3\n",
    "            print(f\"Memory allocated={allocated:.2f} GiB, reserved={reserved:.2f} GiB\")\n",
    "            print(f'First image:')\n",
    "            visualize_image(x[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_function(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_labels.append(y.detach().cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    epoch_accuracy = one_hot_accuracy_score(all_preds, all_labels)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(start_time, model, loader, loss_function):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    num_batches = math.ceil(len(loader.dataset) / config.batch_size)\n",
    "    for batch_number, (x, y) in enumerate(loader):\n",
    "        print(f't={time.time() - start_time:.2f}: Loading validation batch {batch_number + 1}/{num_batches}')\n",
    "\n",
    "        x = x.to(config.device, non_blocking=True)\n",
    "        y = y.to(config.device, non_blocking=True)\n",
    "\n",
    "        if batch_number == 0:\n",
    "            print('First image:')\n",
    "            visualize_image(x[0])\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = loss_function(preds, y)\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_labels.append(y.detach().cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    epoch_accuracy = one_hot_accuracy_score(all_preds, all_labels)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ],
   "id": "7c27b130673a1df8",
   "outputs": [],
   "execution_count": 346
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.832507Z",
     "start_time": "2025-12-05T19:02:23.824998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    config.init(training=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('t=0: Starting data prep and model loading')\n",
    "\n",
    "    run = wandb.init(\n",
    "        project='kenyan_food_classifier',\n",
    "        name=f'run-{int(start_time)}',\n",
    "        config={\n",
    "            'batch_size': config.batch_size,\n",
    "            'learning_rate': config.starting_learning_rate,\n",
    "            'max_epochs': config.max_epochs,\n",
    "            'seed': config.seed,\n",
    "            'model': 'efficientnet_b3',\n",
    "            'optimizer': 'Adam',\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_df = pd.read_csv(config.train_csv_filepath)\n",
    "    train_df['id'] = train_df['id'].astype(str)\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.20,\n",
    "        random_state=config.seed,\n",
    "        shuffle=True,\n",
    "        stratify=train_df['class'],\n",
    "    )\n",
    "\n",
    "    def one_hot_encode_classes(df) -> pd.DataFrame:\n",
    "        one_hot_classes = pd.get_dummies(df['class']).astype(config.np_dtype)\n",
    "        one_hot_df = pd.concat([df['id'], one_hot_classes], axis='columns')\n",
    "        return one_hot_df\n",
    "\n",
    "    train_df = one_hot_encode_classes(train_df)\n",
    "    val_df = one_hot_encode_classes(val_df)\n",
    "\n",
    "    train_ids = train_df['id'].to_numpy()\n",
    "    train_classes = train_df.drop(columns='id').to_numpy()\n",
    "    val_ids = val_df['id'].to_numpy()\n",
    "    val_classes = val_df.drop(columns='id').to_numpy()\n",
    "\n",
    "    model = create_efficient_net_model()\n",
    "\n",
    "    wandb.watch(model, log=\"gradients\", log_freq=100)\n",
    "\n",
    "    train_dataset = ImageClassificationDataset(train_ids, train_classes, config.transforms_train)\n",
    "    val_dataset = ImageClassificationDataset(val_ids, val_classes, config.transforms_val)\n",
    "\n",
    "    def loader(ds, shuffle):\n",
    "        return DataLoader(ds, shuffle=shuffle, batch_size=config.batch_size, num_workers=config.num_workers, pin_memory=config.pin_memory)\n",
    "\n",
    "    train_loader = loader(train_dataset, shuffle=True)\n",
    "    val_loader = loader(val_dataset, shuffle=False)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = TorchOptimizers.Adam(model.parameters(), lr=config.starting_learning_rate)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_accuracy = float('-inf')\n",
    "    best_val_accuracy_epoch = -1\n",
    "    best_state_dict = None\n",
    "    history = dict(train_loss=[], val_loss=[], train_accuracy=[], val_accuracy=[], best_val_loss_epoch=dict())\n",
    "\n",
    "    training_start_time = time.time()\n",
    "    print(f't={training_start_time - start_time:.2f}: Starting training')\n",
    "    torch.manual_seed(config.seed)\n",
    "\n",
    "    epochs_since_best = 0\n",
    "\n",
    "    for epoch in range(1, config.max_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f't={epoch_start_time - start_time:.2f}: Starting epoch {epoch}')\n",
    "        train_loss, train_accuracy = train_one_epoch(start_time, model, train_loader, optimizer, loss_function)\n",
    "        val_loss, val_accuracy = validate_one_epoch(start_time, model, val_loader, loss_function)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "        print(f'================ Epoch {epoch:03d} stats ==================')\n",
    "        print(f'train_loss: {train_loss:.4f}  val_loss: {val_loss:.4f}')\n",
    "        print(f'train_accuracy: {train_accuracy:.4f}  val_accuracy: {val_accuracy:.4f}')\n",
    "        print('===================================================')\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'val_accuracy': val_accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_accuracy_epoch = epoch\n",
    "            epochs_since_best = 0\n",
    "            best_state_dict = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            epochs_since_best += 1\n",
    "            if epochs_since_best >= config.patience:\n",
    "                break\n",
    "\n",
    "    if best_state_dict  is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    history['best_val_loss_epoch']['epoch'] = best_val_loss_epoch\n",
    "    history['best_val_loss_epoch']['val_loss'] = best_val_loss\n",
    "\n",
    "    print()\n",
    "    print('==================== Results ======================')\n",
    "    print(f'Best val accuracy epoch: {best_val_accuracy_epoch}')\n",
    "    print(f'Best val accuracy: {best_val_accuracy:.4f}')\n",
    "    print(f'Best val loss epoch: {best_val_loss_epoch}')\n",
    "    print(f'Best val loss: {best_val_loss:.2f}')\n",
    "    print('===================================================')\n",
    "    print()\n",
    "\n",
    "    wandb.run.summary['best_val_accuracy'] = best_val_accuracy\n",
    "    wandb.run.summary['best_val_accuracy_epoch'] = best_val_accuracy_epoch\n",
    "    wandb.run.summary['best_val_loss'] = best_val_loss\n",
    "    wandb.run.summary['best_val_loss_epoch'] = best_val_loss_epoch\n",
    "\n",
    "    train_loss = history['train_accuracy']\n",
    "    val_loss = history['val_accuracy']\n",
    "    epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.plot(epochs, train_loss, label='train_accuracy', marker='o')\n",
    "    plt.plot(epochs, val_loss, label='val_accuracy', marker='o')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Train vs Validation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    wandb.log({\"accuracy_curve\": wandb.Image(plt.gcf())})\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model.state_dict(), config.training_output_folder + 'model_weights.pth')\n",
    "    with open(config.training_output_folder + 'history.json', 'w') as json_file:\n",
    "        json.dump(history, json_file, indent=4)\n",
    "\n",
    "    wandb.save(config.training_output_folder + 'model_weights.pth')\n",
    "    wandb.save(config.training_output_folder + 'history.json')"
   ],
   "id": "6abb20c94e3db3ef",
   "outputs": [],
   "execution_count": 347
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_saved_model() -> nn.Module:\n",
    "    loaded_model = create_efficient_net_model()\n",
    "    saved_model_weights = torch.load('data_gen/training_output/model_weights.pth', weights_only=True, map_location='cpu')\n",
    "    loaded_model.load_state_dict(saved_model_weights)\n",
    "    loaded_model.eval()\n",
    "    return loaded_model"
   ],
   "id": "ee0192db8f4f1033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def pred_single_image(model, image_id) -> str:\n",
    "    image = config.transforms_val(load_pil_image_from_id(image_id))\n",
    "    image = image.unsqueeze(0) # model expects image batches, so must add a 4th dimension to input image\n",
    "    pred = model(image).detach().cpu().numpy() # one-hot encoded prediction\n",
    "    pred_index = np.argmax(pred, axis=1)[0] # index of highest value among predictions\n",
    "    top_pred = config.classes_list[pred_index]\n",
    "    return top_pred"
   ],
   "id": "4f45d27c645d0c3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.837735Z",
     "start_time": "2025-12-05T19:02:23.834567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_val():\n",
    "    \"\"\" For verifying that the saved weights load and predict correctly on the original validation dataset \"\"\"\n",
    "    config.init(training=False)\n",
    "\n",
    "    train_df = pd.read_csv(config.train_csv_filepath)\n",
    "    train_df['id'] = train_df['id'].astype(str)\n",
    "\n",
    "    _, val_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.20,\n",
    "        random_state=config.seed,\n",
    "        shuffle=True,\n",
    "        stratify=train_df['class'],\n",
    "    )\n",
    "\n",
    "    loaded_model = load_saved_model()\n",
    "\n",
    "    preds_df = pd.DataFrame(columns=['image_id', 'actual', 'pred'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, image_id, true_class in val_df.itertuples():\n",
    "            pred = pred_single_image(loaded_model, image_id)\n",
    "            preds_df.loc[len(preds_df)] = [image_id, true_class, pred]\n",
    "\n",
    "    return preds_df"
   ],
   "id": "6b444f843e3771bb",
   "outputs": [],
   "execution_count": 348
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:02:23.842734Z",
     "start_time": "2025-12-05T19:02:23.838739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_test():\n",
    "    \"\"\" For generating predictions on hidden test set \"\"\"\n",
    "    config.init(training=False)\n",
    "    test_df = pd.read_csv(config.test_csv_filepath)['id'].astype(str)\n",
    "\n",
    "    loaded_model = load_saved_model()\n",
    "\n",
    "    preds_df = pd.DataFrame(columns=['id', 'class'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_id in test_df:\n",
    "            pred = pred_single_image(loaded_model, image_id)\n",
    "            preds_df.loc[len(preds_df)] = [image_id, pred]\n",
    "\n",
    "    preds_df.to_csv(config.submission_filepath, index=False)\n",
    "    return preds_df"
   ],
   "id": "5891be113387a4b0",
   "outputs": [],
   "execution_count": 349
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:03:10.418394Z",
     "start_time": "2025-12-05T19:02:23.861673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = local_config\n",
    "submission_df = predict_test()\n",
    "submission_df"
   ],
   "id": "78ffc03325c5bbe6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        id       class\n",
       "0      9156739011499789258  nyamachoma\n",
       "1      2049465964503133373  kachumbari\n",
       "2      6446998501027132988  nyamachoma\n",
       "3      4194396063119815321       ugali\n",
       "4      9018117998187006009       bhaji\n",
       "...                    ...         ...\n",
       "1633  18302448610371772604     githeri\n",
       "1634  15920672464676076400     chapati\n",
       "1635   3232020170382870007       bhaji\n",
       "1636   3094804487341098468  kachumbari\n",
       "1637   5827342261332058667       ugali\n",
       "\n",
       "[1638 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9156739011499789258</td>\n",
       "      <td>nyamachoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049465964503133373</td>\n",
       "      <td>kachumbari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6446998501027132988</td>\n",
       "      <td>nyamachoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4194396063119815321</td>\n",
       "      <td>ugali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9018117998187006009</td>\n",
       "      <td>bhaji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>18302448610371772604</td>\n",
       "      <td>githeri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>15920672464676076400</td>\n",
       "      <td>chapati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>3232020170382870007</td>\n",
       "      <td>bhaji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>3094804487341098468</td>\n",
       "      <td>kachumbari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>5827342261332058667</td>\n",
       "      <td>ugali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 351
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
