{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.609285Z",
     "start_time": "2025-12-05T16:45:29.186110Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim as TorchOptimizers\n",
    "from torchmetrics import MeanMetric\n",
    "from torchvision import models as torchmodels\n",
    "import torchvision.transforms.v2 as T\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from torchinfo import summary as torch_summary\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.618444Z",
     "start_time": "2025-12-05T16:45:34.613289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    train_csv_filepath: str\n",
    "    test_csv_filepath: str\n",
    "    submission_filepath: str\n",
    "    images_root_folder: str\n",
    "    training_output_folder: str\n",
    "    device: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.fine_tune_start = 5\n",
    "        self.num_classes = 13\n",
    "        self.seed = 201\n",
    "\n",
    "        self.starting_learning_rate = 4e-4\n",
    "        self.max_epochs = 150\n",
    "        self.patience = 10\n",
    "\n",
    "        self.np_dtype = np.float32\n",
    "\n",
    "        self.batch_size = 32\n",
    "        self.num_workers = 4\n",
    "        self.pin_memory = self.num_workers > 0 and self.device == 'cuda'\n",
    "\n",
    "    # noinspection PyAttributeOutsideInit\n",
    "    def init(self, training):\n",
    "        self.training = training\n",
    "        self.imagenet_mean_cpu_tensor = torch.tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_cpu_tensor = torch.tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_cpu_tensor = self.imagenet_mean_cpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_cpu_tensor = self.imagenet_std_cpu_tensor.view(3, 1, 1)\n",
    "        self.imagenet_mean_gpu_tensor = gpu_tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_gpu_tensor = gpu_tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_gpu_tensor = self.imagenet_mean_gpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_gpu_tensor = self.imagenet_std_gpu_tensor.view(3, 1, 1)\n",
    "        self.image_height = 300\n",
    "        self.image_width = 300\n",
    "\n",
    "        os.makedirs(self.training_output_folder, exist_ok=True)\n",
    "\n",
    "        self.image_dims = (self.image_height, self.image_width)\n",
    "\n",
    "        self.transforms_val = T.Compose([\n",
    "            T.Resize(size=self.image_dims, antialias=True),\n",
    "            T.ToImage(),\n",
    "            T.ToDtype(torch.float32, scale=True),\n",
    "            T.Normalize(self.imagenet_mean_cpu_tensor, self.imagenet_std_cpu_tensor),\n",
    "        ])\n",
    "\n",
    "        self.transforms_train = T.Compose([\n",
    "            T.ToImage(),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=180),\n",
    "            T.RandomResizedCrop(\n",
    "                size=self.image_dims,\n",
    "                scale=(0.4, 1.0),\n",
    "                ratio=(0.65, 1.4),\n",
    "                antialias=True,\n",
    "            ),\n",
    "            T.ColorJitter(\n",
    "                brightness=0.4,\n",
    "                contrast=0.4,\n",
    "                saturation=0.3,\n",
    "                hue=0.1,\n",
    "            ),\n",
    "            T.ToDtype(torch.float32, scale=True),\n",
    "            T.Normalize(self.imagenet_mean_cpu_tensor, self.imagenet_std_cpu_tensor),\n",
    "        ])\n",
    "\n",
    "\n",
    "config: Config = None"
   ],
   "id": "13cd238e296dfd3b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.622732Z",
     "start_time": "2025-12-05T16:45:34.620448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local_config = Config(\n",
    "    train_csv_filepath='data/train.csv',\n",
    "    test_csv_filepath='data/test.csv',\n",
    "    images_root_folder='data/images/',\n",
    "    submission_filepath='data_gen/submission.csv',\n",
    "    training_output_folder='data_gen/training_output/',\n",
    "    device='cpu',\n",
    ")\n",
    "kaggle_config = Config(\n",
    "    train_csv_filepath='/kaggle/input/opencv-pytorch-project-2-classification-round-3/train.csv',\n",
    "    test_csv_filepath='/kaggle/input/opencv-pytorch-project-2-classification-round-3/test.csv',\n",
    "    images_root_folder='/kaggle/input/opencv-pytorch-project-2-classification-round-3/images/images/',\n",
    "    submission_filepath='/kaggle/working/submission.csv',\n",
    "    training_output_folder='/kaggle/working/training_output/',\n",
    "    device='cuda',\n",
    ")"
   ],
   "id": "e933b90b9504cc3b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.627885Z",
     "start_time": "2025-12-05T16:45:34.624735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imagenet_mean_array = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "imagenet_std_array = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def gpu_tensor(numpy_array):\n",
    "    return torch.tensor(numpy_array).to(config.device)\n",
    "\n",
    "def visualize_image(image_tensor):\n",
    "    image = denormalize(image_tensor, config.channelwise_imagenet_mean_gpu_tensor, config.channelwise_imagenet_std_gpu_tensor)\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    image = (image * 255).astype('uint8')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    return tensor * std + mean"
   ],
   "id": "3fecf34194bedc1a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.632889Z",
     "start_time": "2025-12-05T16:45:34.629890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ImageClassificationDataset(TorchDataset):\n",
    "    image_ids: np.ndarray\n",
    "    labels: np.ndarray\n",
    "    image_transforms: Callable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_transforms(Image.open(config.images_root_folder + self.image_ids[idx] + '.jpg')), self.labels[idx]"
   ],
   "id": "7a9c60f8ab546924",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.637218Z",
     "start_time": "2025-12-05T16:45:34.635089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_efficient_net_model() -> nn.Module:\n",
    "    weights = 'DEFAULT' if config.training else None\n",
    "    model = torchmodels.efficientnet_b3(weights=weights)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for layer_to_unfreeze in range(config.fine_tune_start, 9):\n",
    "        for param in model.features[layer_to_unfreeze].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3, inplace=True),\n",
    "        nn.Linear(in_features, config.num_classes),\n",
    "    )\n",
    "\n",
    "    model.to(config.device)\n",
    "\n",
    "    return model"
   ],
   "id": "c32ddf467b65552b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.641081Z",
     "start_time": "2025-12-05T16:45:34.639223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_train_df(train_df) -> pd.DataFrame:\n",
    "    one_hot_classes = pd.get_dummies(train_df['class'])\n",
    "    train_df = pd.concat([train_df['id'], one_hot_classes], axis='columns')\n",
    "    return train_df"
   ],
   "id": "88b586ae1e1ea727",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.649532Z",
     "start_time": "2025-12-05T16:45:34.643087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_accuracy_score(preds, y):\n",
    "    preds_argmax = np.argmax(preds, axis=1)\n",
    "    y_argmax = np.argmax(y, axis=1)\n",
    "    return accuracy_score(preds_argmax, y_argmax)\n",
    "\n",
    "def train_one_epoch(start_time, model, loader, optimizer, loss_function):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    num_batches = math.ceil(len(loader.dataset) / config.batch_size)\n",
    "    for batch_number, (x, y) in enumerate(loader):\n",
    "        print(f't={time.time() - start_time:.2f}: Loading training batch {batch_number + 1}/{num_batches}')\n",
    "\n",
    "        x = x.to(config.device, non_blocking=True)\n",
    "        y = y.to(config.device, non_blocking=True)\n",
    "\n",
    "        if batch_number == 0:\n",
    "            allocated = torch.cuda.memory_allocated(config.device) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(config.device) / 1024**3\n",
    "            print(f\"Memory allocated={allocated:.2f} GiB, reserved={reserved:.2f} GiB\")\n",
    "            print(f'First image:')\n",
    "            visualize_image(x[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_function(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_labels.append(y.detach().cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    epoch_accuracy = one_hot_accuracy_score(all_preds, all_labels)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(start_time, model, loader, loss_function):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    num_batches = math.ceil(len(loader.dataset) / config.batch_size)\n",
    "    for batch_number, (x, y) in enumerate(loader):\n",
    "        print(f't={time.time() - start_time:.2f}: Loading validation batch {batch_number + 1}/{num_batches}')\n",
    "\n",
    "        x = x.to(config.device, non_blocking=True)\n",
    "        y = y.to(config.device, non_blocking=True)\n",
    "\n",
    "        if batch_number == 0:\n",
    "            print('First image:')\n",
    "            visualize_image(x[0])\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = loss_function(preds, y)\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_labels.append(y.detach().cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    epoch_accuracy = one_hot_accuracy_score(all_preds, all_labels)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ],
   "id": "7c27b130673a1df8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.658591Z",
     "start_time": "2025-12-05T16:45:34.651536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    config.init(training=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('t=0: Starting data prep and model loading')\n",
    "\n",
    "    train_df = pd.read_csv(config.train_csv_filepath)\n",
    "    train_df['id'] = train_df['id'].astype(str)\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.20,\n",
    "        random_state=config.seed,\n",
    "        shuffle=True,\n",
    "        stratify=train_df['class'],\n",
    "    )\n",
    "\n",
    "    def one_hot_encode_classes(df) -> pd.DataFrame:\n",
    "        one_hot_classes = pd.get_dummies(df['class']).astype(config.np_dtype)\n",
    "        one_hot_df = pd.concat([df['id'], one_hot_classes], axis='columns')\n",
    "        return one_hot_df\n",
    "\n",
    "    train_df = one_hot_encode_classes(train_df)\n",
    "    val_df = one_hot_encode_classes(val_df)\n",
    "\n",
    "    train_ids = train_df['id'].to_numpy()\n",
    "    train_classes = train_df.drop(columns='id').to_numpy()\n",
    "    val_ids = val_df['id'].to_numpy()\n",
    "    val_classes = val_df.drop(columns='id').to_numpy()\n",
    "\n",
    "    model = create_efficient_net_model()\n",
    "\n",
    "    train_dataset = ImageClassificationDataset(train_ids, train_classes, config.transforms_train)\n",
    "    val_dataset = ImageClassificationDataset(val_ids, val_classes, config.transforms_val)\n",
    "\n",
    "    def loader(ds, shuffle):\n",
    "        return DataLoader(ds, shuffle=shuffle, batch_size=config.batch_size, num_workers=config.num_workers, pin_memory=config.pin_memory)\n",
    "\n",
    "    train_loader = loader(train_dataset, shuffle=True)\n",
    "    val_loader = loader(val_dataset, shuffle=False)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = TorchOptimizers.Adam(model.parameters(), lr=config.starting_learning_rate)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_accuracy = float('-inf')\n",
    "    best_val_accuracy_epoch = -1\n",
    "    best_state_dict = None\n",
    "    history = dict(train_loss=[], val_loss=[], train_accuracy=[], val_accuracy=[], best_val_loss_epoch=dict())\n",
    "\n",
    "    training_start_time = time.time()\n",
    "    print(f't={training_start_time - start_time:.2f}: Starting training')\n",
    "    torch.manual_seed(config.seed)\n",
    "\n",
    "    epochs_since_best = 0\n",
    "\n",
    "    for epoch in range(1, config.max_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f't={epoch_start_time - start_time:.2f}: Starting epoch {epoch}')\n",
    "        train_loss, train_accuracy = train_one_epoch(start_time, model, train_loader, optimizer, loss_function)\n",
    "        val_loss, val_accuracy = validate_one_epoch(start_time, model, val_loader, loss_function)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "        print(f'================ Epoch {epoch:03d} stats ==================')\n",
    "        print(f'train_loss: {train_loss:.4f}  val_loss: {val_loss:.4f}')\n",
    "        print(f'train_accuracy: {train_accuracy:.4f}  val_accuracy: {val_accuracy:.4f}')\n",
    "        print('===================================================')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_accuracy_epoch = epoch\n",
    "            epochs_since_best = 0\n",
    "            best_state_dict = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            epochs_since_best += 1\n",
    "            if epochs_since_best >= config.patience:\n",
    "                break\n",
    "\n",
    "    if best_state_dict  is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    history['best_val_loss_epoch']['epoch'] = best_val_loss_epoch\n",
    "    history['best_val_loss_epoch']['val_loss'] = best_val_loss\n",
    "\n",
    "    print()\n",
    "    print('==================== Results ======================')\n",
    "    print(f'Best val accuracy epoch: {best_val_accuracy_epoch}')\n",
    "    print(f'Best val accuracy: {best_val_accuracy:.4f}')\n",
    "    print(f'Best val loss epoch: {best_val_loss_epoch}')\n",
    "    print(f'Best val loss: {best_val_loss:.2f}')\n",
    "    print('===================================================')\n",
    "    print()\n",
    "\n",
    "    train_loss = history['train_accuracy']\n",
    "    val_loss = history['val_accuracy']\n",
    "    epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.plot(epochs, train_loss, label='train_accuracy', marker='o')\n",
    "    plt.plot(epochs, val_loss, label='val_accuracy', marker='o')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Train vs Validation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model.state_dict(), config.training_output_folder + 'model_weights.pth')\n",
    "    with open(config.training_output_folder + 'history.json', 'w') as json_file:\n",
    "        json.dump(history, json_file, indent=4)"
   ],
   "id": "6abb20c94e3db3ef",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:45:34.954692Z",
     "start_time": "2025-12-05T16:45:34.661596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = local_config\n",
    "train()"
   ],
   "id": "7a6fde859d03d24e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0: Starting data prep and model loading\n",
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
      "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
      "      )\n",
      "      (4): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
      "      )\n",
      "      (5): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
      "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
      "            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2dNormActivation(\n",
      "      (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=True)\n",
      "    (1): Linear(in_features=1536, out_features=13, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m config = local_config\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 34\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     31\u001B[39m model = create_efficient_net_model()\n\u001B[32m     33\u001B[39m \u001B[38;5;28mprint\u001B[39m(model)\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     36\u001B[39m train_dataset = ImageClassificationDataset(train_ids, train_classes, config.transforms_train)\n\u001B[32m     37\u001B[39m val_dataset = ImageClassificationDataset(val_ids, val_classes, config.transforms_val)\n",
      "\u001B[31mAssertionError\u001B[39m: "
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
